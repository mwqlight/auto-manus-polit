"""
Use this file to define pytest tests that verify the outputs of the task.

This file will be copied to /tests/test_outputs.py and run by the /tests/test.sh file
from the working directory.
"""

import unittest
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import warnings
from typing import Tuple, Optional

# å¯¼å…¥ABMILå®ç°
from abmil_assignment import ABMIL, Attention_TanhSigmoidGating, basic_test


class TestABMILModel(unittest.TestCase):
    """ABMILæ¨¡å‹çš„å•å…ƒæµ‹è¯•å¥—ä»¶"""
    
    def setUp(self):
        """åœ¨æ¯ä¸ªæµ‹è¯•å‰è®¾ç½®"""
        # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
        torch.manual_seed(42)
        np.random.seed(42)
        
        # åŸºæœ¬é…ç½®
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.input_dim = 512
        self.hidden_dim = 256
        self.n_classes = 2
        self.batch_size = 4
        self.max_instances = 20
        
        # åˆ›å»ºæ¨¡å‹
        self.model = ABMIL(
            input_dim=self.input_dim,
            hidden_dim=self.hidden_dim,
            n_classes=self.n_classes,
            dropout=0.1
        ).to(self.device)
        
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œä½†ä¿ç•™dropoutä»¥ä¾¿æµ‹è¯•
        self.model.train()
    
    def test_basic_forward_pass(self):
        """æµ‹è¯•1: åŸºæœ¬å‰å‘ä¼ æ’­åŠŸèƒ½å’Œè¾“å‡ºå½¢çŠ¶éªŒè¯"""
        print("\nğŸ” æµ‹è¯•1: åŸºæœ¬å‰å‘ä¼ æ’­åŠŸèƒ½")
        
        # åˆ›å»ºéšæœºè¾“å…¥
        x = torch.randn(self.batch_size, self.max_instances, self.input_dim).to(self.device)
        
        # éšæœºbagé•¿åº¦
        lens = torch.randint(1, self.max_instances + 1, (self.batch_size,)).to(self.device)
        
        # å‰å‘ä¼ æ’­
        logits, attn_weights = self.model(x, lens)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        self.assertEqual(logits.shape, (self.batch_size, self.n_classes),
                         f"Logitså½¢çŠ¶é”™è¯¯: æœŸæœ› {(self.batch_size, self.n_classes)}, å¾—åˆ° {logits.shape}")
        
        self.assertEqual(attn_weights.shape, (self.batch_size, self.max_instances),
                         f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶é”™è¯¯: æœŸæœ› {(self.batch_size, self.max_instances)}, å¾—åˆ° {attn_weights.shape}")
        
        # éªŒè¯æ³¨æ„åŠ›æƒé‡æ€§è´¨
        # 1. æ‰€æœ‰æƒé‡åº”ä¸ºéè´Ÿ
        self.assertTrue(torch.all(attn_weights >= 0), "å‘ç°è´Ÿçš„æ³¨æ„åŠ›æƒé‡")
        
        # 2. æ¯ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›æƒé‡æ€»å’Œåº”æ¥è¿‘1 (è€ƒè™‘å¡«å……)
        for i in range(self.batch_size):
            valid_len = lens[i].item()
            weight_sum = attn_weights[i, :valid_len].sum().item()
            self.assertAlmostEqual(weight_sum, 1.0, delta=1e-5,
                                 msg=f"æ ·æœ¬{i}çš„æ³¨æ„åŠ›æƒé‡æ€»å’Œ({weight_sum})ä¸æ¥è¿‘1.0")
        
        print("âœ… åŸºæœ¬å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_edge_cases_and_input_validation(self):
        """æµ‹è¯•2: è¾¹ç•Œæƒ…å†µå’Œè¾“å…¥éªŒè¯"""
        print("\nğŸ” æµ‹è¯•2: è¾¹ç•Œæƒ…å†µå’Œè¾“å…¥éªŒè¯")
        
        # æµ‹è¯•ç”¨ä¾‹1: å•å®ä¾‹bag
        print("  - æµ‹è¯•å•å®ä¾‹bag")
        x_single = torch.randn(1, 1, self.input_dim).to(self.device)
        lens_single = torch.tensor([1]).to(self.device)
        logits, attn_weights = self.model(x_single, lens_single)
        
        self.assertEqual(logits.shape, (1, self.n_classes))
        self.assertEqual(attn_weights.shape, (1, 1))
        self.assertAlmostEqual(attn_weights[0, 0].item(), 1.0, delta=1e-6)
        
        # æµ‹è¯•ç”¨ä¾‹2: æœ€å¤§bagå¤§å° (æ¨¡æ‹Ÿå¤§bag)
        print("  - æµ‹è¯•å¤§bagå¤„ç† (1000ä¸ªå®ä¾‹)")
        large_bag_size = 1000
        x_large = torch.randn(1, large_bag_size, self.input_dim).to(self.device)
        lens_large = torch.tensor([large_bag_size]).to(self.device)
        
        # ç›‘æ§å†…å­˜ä½¿ç”¨
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
            start_mem = torch.cuda.memory_allocated()
        
        logits, attn_weights = self.model(x_large, lens_large)
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ (åº”å°äº500MB)
        if torch.cuda.is_available():
            peak_mem = torch.cuda.max_memory_allocated()
            mem_increase = peak_mem - start_mem
            self.assertLess(mem_increase, 500 * 1024 * 1024,  # 500MB
                           f"å¤§bagå†…å­˜ä½¿ç”¨è¿‡é«˜: {mem_increase / (1024*1024):.2f} MB")
        
        self.assertEqual(logits.shape, (1, self.n_classes))
        self.assertEqual(attn_weights.shape, (1, large_bag_size))
        
        # æµ‹è¯•ç”¨ä¾‹3: æ— æ•ˆè¾“å…¥éªŒè¯
        print("  - æµ‹è¯•æ— æ•ˆè¾“å…¥å¤„ç†")
        
        # æ— æ•ˆç»´åº¦
        with self.assertRaises(ValueError):
            x_invalid = torch.randn(1, self.input_dim).to(self.device)  # ç¼ºå°‘å®ä¾‹ç»´åº¦
            self.model(x_invalid)
        
        # æ— æ•ˆbagé•¿åº¦
        with self.assertRaises(ValueError):
            x_valid = torch.randn(1, 10, self.input_dim).to(self.device)
            lens_invalid = torch.tensor([15]).to(self.device)  # é•¿åº¦è¶…è¿‡å®ä¾‹æ•°
            self.model(x_valid, lens_invalid)
        
        # é›¶é•¿åº¦bag
        with self.assertRaises(ValueError):
            lens_zero = torch.tensor([0]).to(self.device)
            self.model(x_valid, lens_zero)
        
        print("âœ… è¾¹ç•Œæƒ…å†µå’Œè¾“å…¥éªŒè¯æµ‹è¯•é€šè¿‡")
    
    def test_gradient_flow_and_training(self):
        """æµ‹è¯•3: æ¢¯åº¦æµå’Œè®­ç»ƒèƒ½åŠ›"""
        print("\nğŸ” æµ‹è¯•3: æ¢¯åº¦æµå’Œè®­ç»ƒèƒ½åŠ›")
        
        # åˆ›å»ºå°æ‰¹é‡æ•°æ®
        x = torch.randn(self.batch_size, self.max_instances, self.input_dim).to(self.device)
        lens = torch.randint(1, self.max_instances + 1, (self.batch_size,)).to(self.device)
        target = torch.randint(0, self.n_classes, (self.batch_size,)).to(self.device)
        
        # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # å‰å‘ä¼ æ’­
        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
        optimizer.zero_grad()
        
        logits, attn_weights = self.model(x, lens)
        
        # è®¡ç®—æŸå¤±
        loss = F.cross_entropy(logits, target)
        self.assertFalse(torch.isnan(loss) or torch.isinf(loss), "æŸå¤±å€¼æ— æ•ˆ")
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # éªŒè¯æ¢¯åº¦
        grad_norms = []
        for name, param in self.model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_norms.append(grad_norm)
                self.assertFalse(torch.isnan(param.grad).any(), f"å‚æ•°{name}çš„æ¢¯åº¦åŒ…å«NaN")
                self.assertFalse(torch.isinf(param.grad).any(), f"å‚æ•°{name}çš„æ¢¯åº¦åŒ…å«Inf")
                self.assertGreater(grad_norm, 1e-8, f"å‚æ•°{name}çš„æ¢¯åº¦èŒƒæ•°({grad_norm})è¿‡å°")
        
        avg_grad_norm = sum(grad_norms) / len(grad_norms)
        self.assertGreater(avg_grad_norm, 1e-6, f"å¹³å‡æ¢¯åº¦èŒƒæ•°({avg_grad_norm})è¿‡å°ï¼Œæ¢¯åº¦æµå¯èƒ½å­˜åœ¨é—®é¢˜")
        
        # æ‰§è¡Œä¼˜åŒ–æ­¥éª¤
        optimizer.step()
        
        # éªŒè¯å‚æ•°ç¡®å®æ›´æ–°äº†
        new_logits, _ = self.model(x, lens)
        self.assertFalse(torch.allclose(logits, new_logits), "æ¨¡å‹å‚æ•°æœªæ›´æ–°")
        
        print(f"âœ… æ¢¯åº¦æµæµ‹è¯•é€šè¿‡ (å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.6f})")
    
    def test_dtype_and_numerical_stability(self):
        """æµ‹è¯•4: æ•°æ®ç±»å‹æ”¯æŒå’Œæ•°å€¼ç¨³å®šæ€§"""
        print("\nğŸ” æµ‹è¯•4: æ•°æ®ç±»å‹æ”¯æŒå’Œæ•°å€¼ç¨³å®šæ€§")
        
        # æµ‹è¯•ç”¨ä¾‹1: ä¸åŒæ•°æ®ç±»å‹
        dtypes = [torch.float32]
        if torch.cuda.is_available():
            dtypes.extend([torch.float16, torch.float64])
        
        for dtype in dtypes:
            print(f"  - æµ‹è¯•æ•°æ®ç±»å‹: {dtype}")
            model_dtype = self.model.to(dtype)
            x = torch.randn(self.batch_size, self.max_instances, self.input_dim).to(self.device, dtype=dtype)
            lens = torch.randint(1, self.max_instances + 1, (self.batch_size,)).to(self.device)
            
            try:
                logits, attn_weights = model_dtype(x, lens)
                
                # éªŒè¯è¾“å‡ºæ²¡æœ‰NaNæˆ–Inf
                self.assertFalse(torch.isnan(logits).any(), f"{dtype}ä¸‹logitsåŒ…å«NaN")
                self.assertFalse(torch.isinf(logits).any(), f"{dtype}ä¸‹logitsåŒ…å«Inf")
                self.assertFalse(torch.isnan(attn_weights).any(), f"{dtype}ä¸‹æ³¨æ„åŠ›æƒé‡åŒ…å«NaN")
                self.assertFalse(torch.isinf(attn_weights).any(), f"{dtype}ä¸‹æ³¨æ„åŠ›æƒé‡åŒ…å«Inf")
                
                # éªŒè¯æ³¨æ„åŠ›æƒé‡æ€»å’Œ
                for i in range(self.batch_size):
                    valid_len = lens[i].item()
                    weight_sum = attn_weights[i, :valid_len].sum()
                    self.assertTrue(torch.isfinite(weight_sum), f"{dtype}ä¸‹æƒé‡æ€»å’Œä¸ä¸ºæœ‰é™å€¼")
                    self.assertAlmostEqual(weight_sum.item(), 1.0, delta=1e-3 if dtype == torch.float16 else 1e-5,
                                         msg=f"{dtype}ä¸‹æ ·æœ¬{i}çš„æ³¨æ„åŠ›æƒé‡æ€»å’Œä¸æ¥è¿‘1.0")
                
                print(f"    âœ“ {dtype} æµ‹è¯•é€šè¿‡")
                
            except Exception as e:
                print(f"    âŒ {dtype} æµ‹è¯•å¤±è´¥: {str(e)}")
                raise
        
        # æµ‹è¯•ç”¨ä¾‹2: æ•°å€¼ç¨³å®šæ€§ (æç«¯å€¼)
        print("  - æµ‹è¯•æ•°å€¼ç¨³å®šæ€§ (æç«¯å€¼)")
        model_fp32 = self.model.to(torch.float32)
        
        # åˆ›å»ºåŒ…å«æç«¯å€¼çš„è¾“å…¥
        x_extreme = torch.randn(self.batch_size, self.max_instances, self.input_dim).to(self.device)
        # æ·»åŠ ä¸€äº›æå¤§å€¼
        extreme_indices = torch.randint(0, self.batch_size * self.max_instances * self.input_dim, (10,))
        x_extreme.view(-1)[extreme_indices] = 1e6
        
        # æ·»åŠ ä¸€äº›æå°å€¼
        extreme_indices = torch.randint(0, self.batch_size * self.max_instances * self.input_dim, (10,))
        x_extreme.view(-1)[extreme_indices] = -1e6
        
        lens = torch.randint(1, self.max_instances + 1, (self.batch_size,)).to(self.device)
        
        try:
            with warnings.catch_warnings(record=True) as w:
                warnings.simplefilter("always")
                
                logits, attn_weights = model_fp32(x_extreme, lens)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è­¦å‘Š (å…è®¸æœ‰è­¦å‘Šä½†ä¸èƒ½å¤±è´¥)
                if len(w) > 0:
                    print(f"    âš ï¸ æ£€æµ‹åˆ° {len(w)} ä¸ªè­¦å‘Šï¼Œä½†å¤„ç†æˆåŠŸ")
                    for warning in w:
                        print(f"      - {warning.message}")
                
                # éªŒè¯æ²¡æœ‰NaNæˆ–Inf
                self.assertFalse(torch.isnan(logits).any(), "æç«¯å€¼å¯¼è‡´logitsåŒ…å«NaN")
                self.assertFalse(torch.isinf(logits).any(), "æç«¯å€¼å¯¼è‡´logitsåŒ…å«Inf")
                self.assertFalse(torch.isnan(attn_weights).any(), "æç«¯å€¼å¯¼è‡´æ³¨æ„åŠ›æƒé‡åŒ…å«NaN")
                self.assertFalse(torch.isinf(attn_weights).any(), "æç«¯å€¼å¯¼è‡´æ³¨æ„åŠ›æƒé‡åŒ…å«Inf")
            
            print("    âœ“ æç«¯å€¼æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"    âŒ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {str(e)}")
            raise
        
        print("âœ… æ•°æ®ç±»å‹å’Œæ•°å€¼ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
    
    @classmethod
    def tearDownClass(cls):
        """æ‰€æœ‰æµ‹è¯•å®Œæˆåæ¸…ç†"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print("\nğŸ‰ æ‰€æœ‰ABMILæµ‹è¯•å®Œæˆ!")

def test_outputs():
    """Test that the outputs are correct."""
    # é¦–å…ˆè¿è¡Œæä¾›çš„basic_test
    print("ğŸ”§ é¦–å…ˆè¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
    if not basic_test():
        print("âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡è¯¦ç»†å•å…ƒæµ‹è¯•")
        exit(1)
    
    print("\nğŸ§ª å¼€å§‹è¯¦ç»†å•å…ƒæµ‹è¯•...")
    unittest.main(verbosity=2)
